{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HYHdqLgkOZW"
      },
      "source": [
        "### 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48SkdtnegQ4j"
      },
      "outputs": [],
      "source": [
        "!pip install ratsnlp -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt-VtV1dglZL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a_Vq4jhkR4T"
      },
      "source": [
        "### 모델 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXxoMlPDkIzK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from ratsnlp.nlpbook.classification import ClassificationTrainArguments\n",
        "\n",
        "args = ClassificationTrainArguments(\n",
        "    pretrained_model_name= \"beomi/kcbert-base\",\n",
        "    downstream_corpus_name=\"nsmc\",\n",
        "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-doccls\",\n",
        "    downstream_corpus_root_dir=\"/content/Korpora\",\n",
        "    batch_size = 32 if torch.cuda.is_available() else 4,\n",
        "    learning_rate = 5e-5,\n",
        "    max_seq_length = 128,\n",
        "    epochs = 3,\n",
        "    tpu_cores = 0 if torch.cuda.is_available() else 8,\n",
        "    seed = 7\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esJJJkFylOmC"
      },
      "source": [
        "- pretrained_model_name : 프리트레인 마친 언어 모델의 이름(단, 해당 모델이 허깅페이스 모델 허브에 등록되어 있어야 함)\n",
        "\n",
        "- downstream_corpus_name : 다운스트림 데이터의 이름\n",
        "\n",
        "- dowstream_corpus_root_dir : 다운스트림 데이터를 내려받을 위치, 입력하지 않으면 코랩 환경 로컬에 저장\n",
        "\n",
        "- batch_size : 하드웨어 가속기로 GPU를 선택했다면 32, TPU라면 4로 설정, 코랩 환경에서 TPU는 보통 8개의 코어가 할당되는데 batch_size는 코어별로 적용되는 배치 크기\n",
        "\n",
        "- learning_rate : 러닝 레이트, 1회 스텝에서 모델을 얼마나 업데이트 할지에 관한 크기를 가리킴\n",
        "\n",
        "- max_seq_length : 토큰 기준 입력 문장 최대 길이. 이보다 긴 문장은 자르고, 짧은 문장은 동일한 길이를 만들기 위해 스페셜 토큰 ([PAD])를 붙임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EZLAJrMmI53"
      },
      "source": [
        "### 랜덤 시드 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B9xgyNNmKUV"
      },
      "outputs": [],
      "source": [
        "from ratsnlp import nlpbook\n",
        "\n",
        "nlpbook.set_seed(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWyT85BGmObq"
      },
      "outputs": [],
      "source": [
        "nlpbook.set_logger(args) # 각종 로그 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7MReeaJmXcB"
      },
      "source": [
        "### 말뭉치 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCuT7lHRkmqQ"
      },
      "outputs": [],
      "source": [
        "from Korpora import Korpora\n",
        "\n",
        "Korpora.fetch(\n",
        "    corpus_name = args.downstream_corpus_name,\n",
        "    root_dir = args.downstream_corpus_root_dir,\n",
        "    force_download=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koitTff_nY2t"
      },
      "source": [
        "### 토크나이저 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eTz8hRdnVcF"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    do_lower_case = False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLlqt6YynsCW"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B-rOiZnnpc6",
        "outputId": "971905b3-a150-4bc1-8846-10a4c21a90fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 11.658 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 11.658 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 11.658 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 11.658 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 11.658 s]\n"
          ]
        }
      ],
      "source": [
        "from ratsnlp.nlpbook.classification import NsmcCorpus, ClassificationDataset\n",
        "\n",
        "corpus = NsmcCorpus()\n",
        "train_dataset = ClassificationDataset(\n",
        "    args = args,\n",
        "    corpus = corpus,\n",
        "    tokenizer = tokenizer,\n",
        "    mode = \"train\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebd_XVP1oAJW"
      },
      "source": [
        "- ClassificationDataset은 corpus와 토크나이저를 포함\n",
        "\n",
        "- NsmcCorpus는 csv 파일 형식의 nsmc 데이터를 문장과 레이블로 로드\n",
        "\n",
        "- ClassificationDataset은 NsmcCorpus가 넘겨준 문장과 레이블 각각을 모델이 학습할 수 있는 형태로 가공\n",
        "\n",
        "- input_ids, attention_mask, token_types_ids, label(정수로 바뀐 레이블 정보) 확인 가능\n",
        "\n",
        "- ratsgo.github.io/nlpbook/docs/doc_cls/detail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFQlavu_oi6b",
        "outputId": "74dbfe06-28fc-462e-e78f-6d94d1e11e77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationFeatures(input_ids=[2, 2170, 832, 5045, 17, 17, 7992, 29734, 4040, 10720, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6c8Xm-ppXP1"
      },
      "source": [
        "### 학습 데이터 로더 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "L-P-7b4lo3xc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = args.batch_size,\n",
        "    sampler = RandomSampler(train_dataset, replacement = False),\n",
        "    collate_fn = nlpbook.data_collator,\n",
        "    drop_last = False,\n",
        "    num_workers = args.cpu_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4euarf8Hpx6m"
      },
      "source": [
        "- sampler : 샘플링 방식을 정의, 여기서 만든 데이터 로더는 배치를 만들 때 전체 인스턴스 가운데 batch_size 개수 만큼을 비복원 랜덤 추출\n",
        "\n",
        "- collate_fn : 이렇게 뽑은 인스턴스들을 배치로 만드는 역할을 하는 함수. nlpbook.data_collator는 같은 배치에서 인스턴스가 여럿일 때 이를 input_ids, attention_mask 등 종류별로 모으고 파이토치가 요구하는 텐서(tensor) 형태로 바꾸는 역할을 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc7Zmal3qVi7"
      },
      "source": [
        "### 평가용 데이터 로더 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZGE__WApxYH",
        "outputId": "d4c633e0-ac6c-409a-99dc-b4406155e254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 4.170 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 4.170 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 4.170 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 4.170 s]\n",
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 4.170 s]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "val_dataset = ClassificationDataset(\n",
        "    args = args,\n",
        "    corpus = corpus,\n",
        "    tokenizer = tokenizer,\n",
        "    mode = \"test\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4RAujC_qsZJ"
      },
      "source": [
        "- SequentialSampler : 평가용 데이터 로더는 학습용 데이터 로더와 다른 샘플러 사용, 학습 때 배치 구성은 랜덤으로 하는 것이 좋지만, 평가할 때는 평가용 데이터 전체를 쓰기 때문에 굳이 랜덤으로 구성할 이유가 없음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_DjbbicFqrKn"
      },
      "outputs": [],
      "source": [
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = args.batch_size,\n",
        "    sampler = SequentialSampler(val_dataset),\n",
        "    collate_fn = nlpbook.data_collator,\n",
        "    drop_last = False,\n",
        "    num_workers = args.cpu_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iv6KIFWrPxZ"
      },
      "source": [
        "### 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRQamc1SrPIM",
        "outputId": "0681eddf-11f0-45f2-c2fd-28b308bf8492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertForSequenceClassification\n",
        "\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    num_labels = corpus.num_labels\n",
        ")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    config = pretrained_model_config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0BfjsUTtBsN"
      },
      "source": [
        "### 모델 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "vkKA0eOdtAbn"
      },
      "outputs": [],
      "source": [
        "# Task 정의\n",
        "\n",
        "from ratsnlp.nlpbook.classification import ClassificationTask\n",
        "task = ClassificationTask(model, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jci1ETEtV2n",
        "outputId": "8986e025-e19d-4fa7-c71e-6ba7007e5f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = nlpbook.get_trainer(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ULOIEQ7ct0Yh"
      },
      "outputs": [],
      "source": [
        "#trainer.fit(\n",
        "    #task,\n",
        "    #train_dataloaders = train_dataloader,\n",
        "    #val_dataloaders = val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw-sUnEI4sqz"
      },
      "source": [
        "### 실전 투입"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "d_MbbKdAt64h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17287032-eb86-4846-dbe0-df406e47c8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downstream_model_checkpoint_fpath: /gdrive/MyDrive/nlpbook/checkpoint-doccls/epoch=1-val_loss=0.26.ckpt\n"
          ]
        }
      ],
      "source": [
        "from ratsnlp.nlpbook.classification import ClassificationDeployArguments\n",
        "\n",
        "args = ClassificationDeployArguments(\n",
        "    pretrained_model_name = \"beomi/kcbert-base\",\n",
        "    downstream_model_dir=\"/gdrive/MyDrive/nlpbook/checkpoint-doccls\",\n",
        "    max_seq_length = 128\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "PdMFxQqt57B5"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# 토크나이저 로드\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    do_lower_case = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Vx37a8El5L_r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# 체크포인트 로드\n",
        "\n",
        "fine_tuned_model_ckpt = torch.load(\n",
        "    args.downstream_model_checkpoint_fpath,\n",
        "    map_location = torch.device(\"cpu\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "CmYvJfwB6VtE"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "# 파인튜닝 때 사용한 프리트레인 모델 설정값 로드(bert 설정 로드)\n",
        "\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    num_labels = fine_tuned_model_ckpt[\"state_dict\"][\"model.classifier.bias\"].shape.numel(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification \n",
        "\n",
        "# 모델 초기화\n",
        "\n",
        "model = BertForSequenceClassification(pretrained_model_config)"
      ],
      "metadata": {
        "id": "jdGSAN5N9dmH"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 주입\n",
        "\n",
        "model.load_state_dict({k.replace(\"model.\",\"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMqZaW539lKH",
        "outputId": "ca30285c-4d13-4309-f388-17b7b92f92b1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # 평가 모드로 전환"
      ],
      "metadata": {
        "id": "WZY0rMe891bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 출력값 만들고 후처리"
      ],
      "metadata": {
        "id": "xwJ03biG97jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_fn(sentence):\n",
        "  inputs = tokenizer(\n",
        "      [sentence],\n",
        "      max_length = args.max_seq_length,\n",
        "      padding = \"max_length\",\n",
        "      truncation = True\n",
        "  )\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()}) # input을 파이토치 텐서로 변경\n",
        "    prob = outputs.logits.softmax(dim=1)                               # 로짓에 softmax\n",
        "    positive_prob = round(prob[0][1].item(),4)                \n",
        "    negative_prob = round(prob[0][0].item(),4)\n",
        "    pred = \"긍정 (positive) \" if torch.argmax(prob) == 1 else \"부정 (negative) \" # 예측 확률의 최댓값 위치에 따라 pred 제작\n",
        "\n",
        "  return{\n",
        "      'sentence' : sentence,\n",
        "      'pred' : pred,\n",
        "      'positive_data' : f\"긍정 {positive_prob}\",\n",
        "      'negative_data' : f\"부정 {negative_prob}\",\n",
        "      'positive_data' : f\"{positive_prob * 100}%\",\n",
        "      'negative_data' : f\"{negative_prob * 100}%\",\n",
        "  }"
      ],
      "metadata": {
        "id": "TF_t_7EG961_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 로짓 : 로짓 함수는 0에서 1까지의 확률값과 -∞에서 ∞ 사이의 확률값을 표현해주는 함수로, X축이 아니라 Y축에서 0과 1 사이의 값을 제한하는 시그모이드 함수에 대한 역함수 \n",
        "\n",
        "- 로짓 함수는 0 - 1의 도메인 내에 존재하기 때문에 이 함수는 확률을 이해하는 데 가장 일반적으로 사용"
      ],
      "metadata": {
        "id": "0KStoneiDxml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 웹 서비스 시작하기"
      ],
      "metadata": {
        "id": "rOB6yfEj_E5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ratsnlp.nlpbook.classification import get_web_service_app\n",
        "\n",
        "app = get_web_service_app(inference_fn)\n",
        "app.run() # 실행 안됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djukeGJB-IX3",
        "outputId": "32e83f73-0baf-4415-f7ce-07e9fc4bd27a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"ratsnlp.nlpbook.classification.deploy\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://7073-34-121-220-248.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:10:00] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:10:01] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:11:09] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:11:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:12:21] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:12:22] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:13:35] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:13:35] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:13:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:13:40] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:15:47] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:15:47] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ChQ03o3_Qqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
