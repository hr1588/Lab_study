{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 모델이 예측값 구하는 방식\n",
    "\n",
    "- 순전파(Forward propagation) : 입력 값을 바탕으로 출력 값을 계산하는 과정\n",
    "\n",
    "- 활성화 함수는 비선형 함수(sigmoid, relu, softmax, ...)\n",
    "- 순전파를 사용하면 예측값과 실제값 간의 오차값을 구하여 loss function을 구할 수 있음\n",
    "- 최적화 방법 => Gradient descent : 가중치를 loss function 값이 작아지게 업데이트\n",
    "- Gradient 값은 각 가중치 마다 정하지며, 역전파를 통하여 구할 수 있음\n",
    "- 역전파 : Forward propagation의 반대 방향으로 이뤄지는 과정\n",
    "\n",
    "### 딥러닝 모델의 학습 순서\n",
    "\n",
    "1. 학습용 feature 데이터를 입력하여 예측값 구하기(순전파)\n",
    "2. 예측값과 실제값 사이의 오차 구하기(Loss 계산)\n",
    "3. Loss를 줄일 수 있는 가중치 업데이트 하기(역전파)\n",
    "4. 1-3번 반복으로 Loss를 최소로 하는 가중치 얻기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Epoch : 한 번의 에폭은 전체 데이터 셋에 대해 한 번 학습을 완료한 상태\n",
    "- Batch : 나눠진 데이터 셋(보통 mini-batch라고 표현)\n",
    "- iteration : epoch을 나누어서 실행하는 횟수\n",
    "\n",
    "ex) 총 데이터가 천개, batch size가 100이면\n",
    "- 1 iteration = 100개 데이터에 대해 학습\n",
    "- 1 epoch = 10 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # warning 메시지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     TV  Radio  Newspaper  Sales\n",
       "0      1  230.1   37.8       69.2   22.1\n",
       "1      2   44.5   39.3       45.1   10.4\n",
       "2      3   17.2   45.9       69.3    9.3\n",
       "3      4  151.5   41.3       58.5   18.5\n",
       "4      5  180.8   10.8       58.4   12.9\n",
       "..   ...    ...    ...        ...    ...\n",
       "195  196   38.2    3.7       13.8    7.6\n",
       "196  197   94.2    4.9        8.1    9.7\n",
       "197  198  177.0    9.3        6.4   12.8\n",
       "198  199  283.6   42.0       66.2   25.5\n",
       "199  200  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Advertising.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ID'])\n",
    "\n",
    "x = df.drop(columns = ['Sales'])\n",
    "y = df['Sales']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)) # 학습용 데이터를 tf.data.Dataset 형태로 변환\n",
    "train_ds = train_ds.shuffle(len(train_x)).batch(batch_size=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(train_features_batch, label_batch)] = train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FB, TV, Newspaper batch 데이터:\n",
      " tf.Tensor(\n",
      "[[191.1  28.7  18.2]\n",
      " [215.4  23.6  57.6]\n",
      " [165.6  10.   17.6]\n",
      " [204.1  32.9  46. ]\n",
      " [187.9  17.2  17.9]], shape=(5, 3), dtype=float64)\n",
      "Sales batch 데이터: tf.Tensor([17.3 17.1 12.6 19.  14.7], shape=(5,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print('FB, TV, Newspaper batch 데이터:\\n',train_features_batch)\n",
    "print('Sales batch 데이터:',label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "- 모델 클래스 객체 생성 : tf.keras.models.Sequential() / 괄호안에 layer 삽입\n",
    "- tf.keras.layers.Dense(units, activation)\n",
    "- units : 레이어 안의 노드 수\n",
    "- activation : 적용할 활성화 함수 설정\n",
    "\n",
    "- input layer는 입력 형태에 대한 정보를 필요로 함 (input_shape / input_dim 인자 설정)\n",
    "- 제일 처음 레이어에는 input_dim을 지정해야 함, 뒤에는 상관없음\n",
    "\n",
    "- 모델 학습 방식을 설정하기 위한 함수 : model.compile(optimizer, loss)\n",
    "- optimizer : 모델 학습 최적화 방법 / loss : 손실 함수 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                40        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 - 1s - loss: 11479.0205 - 1s/epoch - 47ms/step\n",
      "Epoch 2/100\n",
      "28/28 - 0s - loss: 6124.6172 - 58ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "28/28 - 0s - loss: 2981.0273 - 82ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "28/28 - 0s - loss: 1349.9916 - 64ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "28/28 - 0s - loss: 619.5861 - 94ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "28/28 - 0s - loss: 351.7637 - 95ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "28/28 - 0s - loss: 249.6100 - 99ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "28/28 - 0s - loss: 210.8315 - 95ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "28/28 - 0s - loss: 185.8766 - 99ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "28/28 - 0s - loss: 164.4078 - 83ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "28/28 - 0s - loss: 143.8389 - 67ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "28/28 - 0s - loss: 126.7281 - 64ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "28/28 - 0s - loss: 110.5307 - 67ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "28/28 - 0s - loss: 95.9788 - 70ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "28/28 - 0s - loss: 82.5905 - 62ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "28/28 - 0s - loss: 71.5601 - 62ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "28/28 - 0s - loss: 61.6532 - 67ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "28/28 - 0s - loss: 52.7034 - 59ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "28/28 - 0s - loss: 45.3934 - 67ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "28/28 - 0s - loss: 39.0125 - 69ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "28/28 - 0s - loss: 32.9423 - 77ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "28/28 - 0s - loss: 28.4967 - 75ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "28/28 - 0s - loss: 24.3319 - 72ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "28/28 - 0s - loss: 20.8031 - 68ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "28/28 - 0s - loss: 17.8440 - 63ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "28/28 - 0s - loss: 15.5032 - 59ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "28/28 - 0s - loss: 13.4382 - 80ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "28/28 - 0s - loss: 11.8103 - 67ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "28/28 - 0s - loss: 10.3916 - 66ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "28/28 - 0s - loss: 9.2128 - 62ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "28/28 - 0s - loss: 8.3244 - 58ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "28/28 - 0s - loss: 7.6075 - 56ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "28/28 - 0s - loss: 6.9582 - 78ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "28/28 - 0s - loss: 6.4944 - 65ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "28/28 - 0s - loss: 6.0748 - 62ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "28/28 - 0s - loss: 5.6991 - 62ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "28/28 - 0s - loss: 5.4684 - 65ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "28/28 - 0s - loss: 5.2632 - 78ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "28/28 - 0s - loss: 5.0443 - 57ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "28/28 - 0s - loss: 4.9324 - 82ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "28/28 - 0s - loss: 4.7664 - 80ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "28/28 - 0s - loss: 4.6781 - 71ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "28/28 - 0s - loss: 4.5954 - 65ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "28/28 - 0s - loss: 4.5332 - 58ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "28/28 - 0s - loss: 4.4682 - 68ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "28/28 - 0s - loss: 4.4188 - 66ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "28/28 - 0s - loss: 4.3502 - 84ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "28/28 - 0s - loss: 4.3241 - 98ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "28/28 - 0s - loss: 4.2409 - 66ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "28/28 - 0s - loss: 4.2072 - 68ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "28/28 - 0s - loss: 4.1827 - 66ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "28/28 - 0s - loss: 4.1313 - 68ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "28/28 - 0s - loss: 4.1274 - 77ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "28/28 - 0s - loss: 4.0909 - 68ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "28/28 - 0s - loss: 4.0785 - 70ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "28/28 - 0s - loss: 4.0705 - 65ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "28/28 - 0s - loss: 4.0266 - 73ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "28/28 - 0s - loss: 4.0279 - 75ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "28/28 - 0s - loss: 3.9985 - 80ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "28/28 - 0s - loss: 3.9752 - 67ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "28/28 - 0s - loss: 3.9750 - 63ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "28/28 - 0s - loss: 3.9713 - 65ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "28/28 - 0s - loss: 3.9443 - 68ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "28/28 - 0s - loss: 3.9340 - 67ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "28/28 - 0s - loss: 3.9293 - 66ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "28/28 - 0s - loss: 3.9141 - 68ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "28/28 - 0s - loss: 3.9127 - 78ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "28/28 - 0s - loss: 3.8980 - 66ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "28/28 - 0s - loss: 3.8791 - 86ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "28/28 - 0s - loss: 3.9011 - 69ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "28/28 - 0s - loss: 3.8930 - 59ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "28/28 - 0s - loss: 3.9074 - 82ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "28/28 - 0s - loss: 3.8756 - 82ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "28/28 - 0s - loss: 3.8552 - 61ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "28/28 - 0s - loss: 3.8527 - 62ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "28/28 - 0s - loss: 3.8787 - 68ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "28/28 - 0s - loss: 3.8337 - 69ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "28/28 - 0s - loss: 3.8451 - 67ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "28/28 - 0s - loss: 3.8289 - 86ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "28/28 - 0s - loss: 3.8109 - 84ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "28/28 - 0s - loss: 3.8142 - 101ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "28/28 - 0s - loss: 3.8252 - 67ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "28/28 - 0s - loss: 3.8542 - 76ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "28/28 - 0s - loss: 3.8347 - 76ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "28/28 - 0s - loss: 3.8237 - 66ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "28/28 - 0s - loss: 3.8247 - 72ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "28/28 - 0s - loss: 3.8011 - 73ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "28/28 - 0s - loss: 3.8112 - 72ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "28/28 - 0s - loss: 3.7859 - 83ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "28/28 - 0s - loss: 3.8160 - 70ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "28/28 - 0s - loss: 3.7652 - 66ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "28/28 - 0s - loss: 3.8264 - 69ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "28/28 - 0s - loss: 3.7836 - 71ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "28/28 - 0s - loss: 3.7488 - 61ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "28/28 - 0s - loss: 3.7762 - 62ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "28/28 - 0s - loss: 3.7913 - 110ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "28/28 - 0s - loss: 3.8338 - 102ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "28/28 - 0s - loss: 3.7593 - 62ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "28/28 - 0s - loss: 3.7550 - 63ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "28/28 - 0s - loss: 3.7306 - 84ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape = (3,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
    "history = model.fit(train_ds, epochs = 100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5272\n",
      "0 번째 테스트 데이터의 실제값: 13.400000\n",
      "1 번째 테스트 데이터의 실제값: 13.200000\n",
      "2 번째 테스트 데이터의 실제값: 15.000000\n",
      "3 번째 테스트 데이터의 실제값: 9.900000\n",
      "4 번째 테스트 데이터의 실제값: 26.200000\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(test_x, test_y) # 데스트 데이터 loss값 확인\n",
    "for i in range(5) :\n",
    "    print(\"%d 번째 테스트 데이터의 실제값: %f\" % (i, test_y.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "0 번째 테스트 데이터의 실제값: 14.415457\n",
      "1 번째 테스트 데이터의 실제값: 11.899427\n",
      "2 번째 테스트 데이터의 실제값: 17.523085\n",
      "3 번째 테스트 데이터의 실제값: 6.627179\n",
      "4 번째 테스트 데이터의 실제값: 26.404284\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_x) # 모델 예측 결과\n",
    "for i in range(5) :\n",
    "    print(\"%d 번째 테스트 데이터의 실제값: %f\" % (i, pred[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 loss :  4.527188777923584\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(test_x,test_y,verbose = 0)\n",
    "print(\"테스트 데이터의 loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 모델로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "x,y = load_iris(return_X_y=True)\n",
    "df = pd.DataFrame(x, columns = ['꽃받침 길이','꽃받침 넓이','꽃잎 길이','꽃잎 넓이'])\n",
    "df['클래스'] = y\n",
    "\n",
    "x = df.drop(columns = ['클래스'])\n",
    "y = df['클래스']\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x.values, train_y))\n",
    "train_ds = train_ds.shuffle(len(train_x)).batch(batch_size = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 - 1s - loss: 1.5087 - accuracy: 0.2667 - 705ms/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "24/24 - 0s - loss: 1.3371 - accuracy: 0.1750 - 59ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "24/24 - 0s - loss: 1.2300 - accuracy: 0.2083 - 93ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "24/24 - 0s - loss: 1.1335 - accuracy: 0.2333 - 94ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "24/24 - 0s - loss: 1.0436 - accuracy: 0.3333 - 80ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "24/24 - 0s - loss: 0.9717 - accuracy: 0.5417 - 102ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "24/24 - 0s - loss: 0.9061 - accuracy: 0.6250 - 87ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "24/24 - 0s - loss: 0.8522 - accuracy: 0.6083 - 72ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "24/24 - 0s - loss: 0.8004 - accuracy: 0.6417 - 83ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "24/24 - 0s - loss: 0.7634 - accuracy: 0.6417 - 60ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "24/24 - 0s - loss: 0.7227 - accuracy: 0.6250 - 83ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "24/24 - 0s - loss: 0.6964 - accuracy: 0.6750 - 71ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "24/24 - 0s - loss: 0.6637 - accuracy: 0.7000 - 88ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "24/24 - 0s - loss: 0.6376 - accuracy: 0.7000 - 97ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "24/24 - 0s - loss: 0.6284 - accuracy: 0.6917 - 87ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "24/24 - 0s - loss: 0.5983 - accuracy: 0.7750 - 78ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "24/24 - 0s - loss: 0.5875 - accuracy: 0.7000 - 74ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "24/24 - 0s - loss: 0.5670 - accuracy: 0.7917 - 76ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "24/24 - 0s - loss: 0.5487 - accuracy: 0.7500 - 71ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "24/24 - 0s - loss: 0.5446 - accuracy: 0.7917 - 60ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "24/24 - 0s - loss: 0.5246 - accuracy: 0.7833 - 67ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "24/24 - 0s - loss: 0.5086 - accuracy: 0.8500 - 63ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "24/24 - 0s - loss: 0.4987 - accuracy: 0.8667 - 75ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "24/24 - 0s - loss: 0.4877 - accuracy: 0.8750 - 67ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "24/24 - 0s - loss: 0.4767 - accuracy: 0.8583 - 65ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "24/24 - 0s - loss: 0.4759 - accuracy: 0.7917 - 97ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "24/24 - 0s - loss: 0.4656 - accuracy: 0.9000 - 59ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "24/24 - 0s - loss: 0.4494 - accuracy: 0.9000 - 56ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "24/24 - 0s - loss: 0.4414 - accuracy: 0.8667 - 68ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "24/24 - 0s - loss: 0.4343 - accuracy: 0.9083 - 68ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "24/24 - 0s - loss: 0.4237 - accuracy: 0.9333 - 66ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "24/24 - 0s - loss: 0.4168 - accuracy: 0.9417 - 80ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "24/24 - 0s - loss: 0.4081 - accuracy: 0.9333 - 81ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "24/24 - 0s - loss: 0.4031 - accuracy: 0.9417 - 86ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "24/24 - 0s - loss: 0.3934 - accuracy: 0.9583 - 86ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "24/24 - 0s - loss: 0.3910 - accuracy: 0.9417 - 79ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "24/24 - 0s - loss: 0.3835 - accuracy: 0.9667 - 70ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "24/24 - 0s - loss: 0.3725 - accuracy: 0.9500 - 53ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "24/24 - 0s - loss: 0.3663 - accuracy: 0.9500 - 64ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "24/24 - 0s - loss: 0.3608 - accuracy: 0.9583 - 60ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "24/24 - 0s - loss: 0.3620 - accuracy: 0.9333 - 60ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "24/24 - 0s - loss: 0.3526 - accuracy: 0.9417 - 71ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "24/24 - 0s - loss: 0.3422 - accuracy: 0.9667 - 65ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "24/24 - 0s - loss: 0.3342 - accuracy: 0.9583 - 85ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "24/24 - 0s - loss: 0.3294 - accuracy: 0.9667 - 97ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "24/24 - 0s - loss: 0.3234 - accuracy: 0.9667 - 56ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "24/24 - 0s - loss: 0.3187 - accuracy: 0.9750 - 65ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "24/24 - 0s - loss: 0.3199 - accuracy: 0.9583 - 53ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "24/24 - 0s - loss: 0.3104 - accuracy: 0.9583 - 58ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "24/24 - 0s - loss: 0.3057 - accuracy: 0.9583 - 59ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "24/24 - 0s - loss: 0.2962 - accuracy: 0.9750 - 63ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "24/24 - 0s - loss: 0.2940 - accuracy: 0.9750 - 46ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "24/24 - 0s - loss: 0.2896 - accuracy: 0.9667 - 80ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "24/24 - 0s - loss: 0.2825 - accuracy: 0.9750 - 55ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "24/24 - 0s - loss: 0.2832 - accuracy: 0.9667 - 99ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "24/24 - 0s - loss: 0.2768 - accuracy: 0.9667 - 90ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "24/24 - 0s - loss: 0.2684 - accuracy: 0.9667 - 77ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "24/24 - 0s - loss: 0.2690 - accuracy: 0.9667 - 71ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "24/24 - 0s - loss: 0.2727 - accuracy: 0.9583 - 79ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "24/24 - 0s - loss: 0.2587 - accuracy: 0.9750 - 85ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "24/24 - 0s - loss: 0.2578 - accuracy: 0.9667 - 64ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "24/24 - 0s - loss: 0.2487 - accuracy: 0.9750 - 68ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "24/24 - 0s - loss: 0.2567 - accuracy: 0.9667 - 65ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "24/24 - 0s - loss: 0.2467 - accuracy: 0.9583 - 79ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "24/24 - 0s - loss: 0.2396 - accuracy: 0.9583 - 85ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "24/24 - 0s - loss: 0.2484 - accuracy: 0.9500 - 52ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "24/24 - 0s - loss: 0.2308 - accuracy: 0.9583 - 79ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "24/24 - 0s - loss: 0.2313 - accuracy: 0.9750 - 82ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "24/24 - 0s - loss: 0.2293 - accuracy: 0.9667 - 76ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "24/24 - 0s - loss: 0.2217 - accuracy: 0.9667 - 78ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "24/24 - 0s - loss: 0.2157 - accuracy: 0.9833 - 81ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "24/24 - 0s - loss: 0.2128 - accuracy: 0.9750 - 70ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "24/24 - 0s - loss: 0.2109 - accuracy: 0.9667 - 64ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "24/24 - 0s - loss: 0.2076 - accuracy: 0.9833 - 72ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "24/24 - 0s - loss: 0.2093 - accuracy: 0.9667 - 92ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "24/24 - 0s - loss: 0.2010 - accuracy: 0.9667 - 81ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "24/24 - 0s - loss: 0.2035 - accuracy: 0.9667 - 80ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "24/24 - 0s - loss: 0.1997 - accuracy: 0.9750 - 69ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "24/24 - 0s - loss: 0.1945 - accuracy: 0.9833 - 68ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "24/24 - 0s - loss: 0.1921 - accuracy: 0.9750 - 86ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "24/24 - 0s - loss: 0.1894 - accuracy: 0.9833 - 74ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "24/24 - 0s - loss: 0.1855 - accuracy: 0.9833 - 71ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "24/24 - 0s - loss: 0.1857 - accuracy: 0.9750 - 66ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "24/24 - 0s - loss: 0.1811 - accuracy: 0.9833 - 64ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "24/24 - 0s - loss: 0.1785 - accuracy: 0.9833 - 86ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "24/24 - 0s - loss: 0.1769 - accuracy: 0.9750 - 74ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "24/24 - 0s - loss: 0.1763 - accuracy: 0.9750 - 87ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "24/24 - 0s - loss: 0.1725 - accuracy: 0.9833 - 110ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "24/24 - 0s - loss: 0.1708 - accuracy: 0.9750 - 77ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "24/24 - 0s - loss: 0.1696 - accuracy: 0.9833 - 52ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "24/24 - 0s - loss: 0.1689 - accuracy: 0.9667 - 84ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "24/24 - 0s - loss: 0.1664 - accuracy: 0.9750 - 75ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "24/24 - 0s - loss: 0.1668 - accuracy: 0.9833 - 96ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "24/24 - 0s - loss: 0.1610 - accuracy: 0.9833 - 69ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "24/24 - 0s - loss: 0.1618 - accuracy: 0.9667 - 56ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "24/24 - 0s - loss: 0.1589 - accuracy: 0.9833 - 71ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "24/24 - 0s - loss: 0.1577 - accuracy: 0.9750 - 96ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "24/24 - 0s - loss: 0.1603 - accuracy: 0.9667 - 68ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "24/24 - 0s - loss: 0.1555 - accuracy: 0.9750 - 67ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "24/24 - 0s - loss: 0.1528 - accuracy: 0.9833 - 97ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, input_dim = 4),\n",
    "    keras.layers.Dense(3, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_ds, epochs = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1681 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "테스트 데이터의 accuracy :  0.9333333373069763\n",
      "0 번째 테스트 데이터의 실제값 : 1\n",
      "0 번째 테스트 데이터 예측값: 1\n",
      "1 번째 테스트 데이터의 실제값 : 0\n",
      "1 번째 테스트 데이터 예측값: 0\n",
      "2 번째 테스트 데이터의 실제값 : 2\n",
      "2 번째 테스트 데이터 예측값: 2\n",
      "3 번째 테스트 데이터의 실제값 : 1\n",
      "3 번째 테스트 데이터 예측값: 1\n",
      "4 번째 테스트 데이터의 실제값 : 1\n",
      "4 번째 테스트 데이터 예측값: 1\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "pred = model.predict(test_x)\n",
    "\n",
    "print(\"테스트 데이터의 accuracy : \", acc)\n",
    "for i in range(5):\n",
    "    print(\"%d 번째 테스트 데이터의 실제값 : %d\" % (i, test_y.iloc[i]))\n",
    "    print(\"%d 번째 테스트 데이터 예측값: %d\" % (i, np.argmax(pred[i])))\n",
    "    \n",
    "# np.argmax 함수는 함수 내에 array와 비슷한 형태(리스트 등 포함)의 input을 넣어주면 가장 큰 원소의 인덱스를 반환하는 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43af7393c8e3bb0730eb35f197fc5ab4355397fc73467075a0f020e747dbc619"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
